{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"politifact_with_bio_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>name</th>\n",
       "      <th>claim_date</th>\n",
       "      <th>claim_source</th>\n",
       "      <th>claim</th>\n",
       "      <th>issue</th>\n",
       "      <th>accuracy_rating</th>\n",
       "      <th>id.bioguide</th>\n",
       "      <th>id.wikipedia</th>\n",
       "      <th>bio.gender</th>\n",
       "      <th>bio.birthday</th>\n",
       "      <th>type</th>\n",
       "      <th>party</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>state</th>\n",
       "      <th>full_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>August 5, 2022</td>\n",
       "      <td>an ad</td>\n",
       "      <td>Blake Masters “wants to pass a national ban on...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>K000377</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>M</td>\n",
       "      <td>21/2/1964</td>\n",
       "      <td>sen</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>2/12/2020</td>\n",
       "      <td>3/1/2023</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Mark Kelly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>Mariannette Miller-Meeks</td>\n",
       "      <td>July 17, 2022</td>\n",
       "      <td>a newsletter</td>\n",
       "      <td>The Democrats’ Women’s Health Protection Act o...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>M001215</td>\n",
       "      <td>Mariannette Miller-Meeks</td>\n",
       "      <td>F</td>\n",
       "      <td>6/9/1955</td>\n",
       "      <td>rep</td>\n",
       "      <td>Republican</td>\n",
       "      <td>3/1/2021</td>\n",
       "      <td>3/1/2023</td>\n",
       "      <td>IA</td>\n",
       "      <td>Mariannette Miller-Meeks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>Catherine Cortez Masto</td>\n",
       "      <td>June 14, 2022</td>\n",
       "      <td>an ad</td>\n",
       "      <td>Adam Laxalt \"supports eliminating Nevada's pro...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>half-true</td>\n",
       "      <td>C001113</td>\n",
       "      <td>Catherine Cortez Masto</td>\n",
       "      <td>F</td>\n",
       "      <td>29/3/1964</td>\n",
       "      <td>sen</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>3/1/2017</td>\n",
       "      <td>3/1/2023</td>\n",
       "      <td>NV</td>\n",
       "      <td>Catherine Cortez Masto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>Tammy Baldwin</td>\n",
       "      <td>May 4, 2022</td>\n",
       "      <td>TV interview</td>\n",
       "      <td>\"Our Supreme Court has never taken away a cons...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>B001230</td>\n",
       "      <td>Tammy Baldwin</td>\n",
       "      <td>F</td>\n",
       "      <td>11/2/1962</td>\n",
       "      <td>rep</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>6/1/1999</td>\n",
       "      <td>3/1/2001</td>\n",
       "      <td>WI</td>\n",
       "      <td>Tammy Baldwin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>Ron Johnson</td>\n",
       "      <td>May 11, 2022</td>\n",
       "      <td>News release</td>\n",
       "      <td>In the immediate wake of a fire and vandalism ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>J000293</td>\n",
       "      <td>Ron Johnson (Wisconsin politician)</td>\n",
       "      <td>M</td>\n",
       "      <td>8/4/1955</td>\n",
       "      <td>sen</td>\n",
       "      <td>Republican</td>\n",
       "      <td>5/1/2011</td>\n",
       "      <td>3/1/2017</td>\n",
       "      <td>WI</td>\n",
       "      <td>Ron Johnson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index  Unnamed: 0.1                      name      claim_date  \\\n",
       "0           0      2             2                Mark Kelly  August 5, 2022   \n",
       "1           1      9             9  Mariannette Miller-Meeks   July 17, 2022   \n",
       "2           2     25            25    Catherine Cortez Masto   June 14, 2022   \n",
       "3           3     28            28             Tammy Baldwin     May 4, 2022   \n",
       "4           4     29            29               Ron Johnson    May 11, 2022   \n",
       "\n",
       "   claim_source                                              claim     issue  \\\n",
       "0         an ad  Blake Masters “wants to pass a national ban on...  abortion   \n",
       "1  a newsletter  The Democrats’ Women’s Health Protection Act o...  abortion   \n",
       "2         an ad  Adam Laxalt \"supports eliminating Nevada's pro...  abortion   \n",
       "3  TV interview  \"Our Supreme Court has never taken away a cons...  abortion   \n",
       "4  News release  In the immediate wake of a fire and vandalism ...  abortion   \n",
       "\n",
       "  accuracy_rating id.bioguide                        id.wikipedia bio.gender  \\\n",
       "0     mostly-true     K000377                          Mark Kelly          M   \n",
       "1     barely-true     M001215            Mariannette Miller-Meeks          F   \n",
       "2       half-true     C001113              Catherine Cortez Masto          F   \n",
       "3           FALSE     B001230                       Tammy Baldwin          F   \n",
       "4     barely-true     J000293  Ron Johnson (Wisconsin politician)          M   \n",
       "\n",
       "  bio.birthday type       party      start       end state  \\\n",
       "0    21/2/1964  sen    Democrat  2/12/2020  3/1/2023    AZ   \n",
       "1     6/9/1955  rep  Republican   3/1/2021  3/1/2023    IA   \n",
       "2    29/3/1964  sen    Democrat   3/1/2017  3/1/2023    NV   \n",
       "3    11/2/1962  rep    Democrat   6/1/1999  3/1/2001    WI   \n",
       "4     8/4/1955  sen  Republican   5/1/2011  3/1/2017    WI   \n",
       "\n",
       "                  full_name  accuracy  \n",
       "0                Mark Kelly         1  \n",
       "1  Mariannette Miller-Meeks         0  \n",
       "2    Catherine Cortez Masto         0  \n",
       "3             Tammy Baldwin         0  \n",
       "4               Ron Johnson         0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop rows of the same claim but categorised under different issues to avoid data leakage when splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are: (6396, 20)\n",
      "but only 4027 unique claims\n"
     ]
    }
   ],
   "source": [
    "print(\"there are: {rows}\".format(rows=df1.shape))\n",
    "print(\"but only {n} unique claims\".format(n=df1['claim'].unique().__len__()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection this is the result of politcas grouping the same article under different issues. The duplicates need to be removed to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop_duplicates(subset=['claim'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = df2['claim']\n",
    "issues = []\n",
    "for c in claims:\n",
    "    issues.append(' '.join(df1[df1['claim']==c]['issue'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Loh Dai Jiu\\AppData\\Local\\Temp\\ipykernel_27452\\3057121005.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['issues'] = issues\n"
     ]
    }
   ],
   "source": [
    "df2['issues'] = issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df2\n",
    "df1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4027, 22)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_date</th>\n",
       "      <th>claim_date_formatted</th>\n",
       "      <th>bio.birthday</th>\n",
       "      <th>birthdate_formatted</th>\n",
       "      <th>start</th>\n",
       "      <th>start_formatted</th>\n",
       "      <th>end</th>\n",
       "      <th>end_formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>January 20, 2012</td>\n",
       "      <td>2012-01-20</td>\n",
       "      <td>19/11/1947</td>\n",
       "      <td>1947-11-19</td>\n",
       "      <td>6/1/1987</td>\n",
       "      <td>1987-01-06</td>\n",
       "      <td>3/1/1989</td>\n",
       "      <td>1989-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>May 14, 2012</td>\n",
       "      <td>2012-05-14</td>\n",
       "      <td>27/2/1954</td>\n",
       "      <td>1954-02-27</td>\n",
       "      <td>4/1/1995</td>\n",
       "      <td>1995-01-04</td>\n",
       "      <td>3/1/1997</td>\n",
       "      <td>1997-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>November 5, 2010</td>\n",
       "      <td>2010-11-05</td>\n",
       "      <td>17/11/1949</td>\n",
       "      <td>1949-11-17</td>\n",
       "      <td>3/1/1991</td>\n",
       "      <td>1991-01-03</td>\n",
       "      <td>3/1/1993</td>\n",
       "      <td>1993-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>November 19, 2020</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>11/2/1962</td>\n",
       "      <td>1962-02-11</td>\n",
       "      <td>6/1/1999</td>\n",
       "      <td>1999-01-06</td>\n",
       "      <td>3/1/2001</td>\n",
       "      <td>2001-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>July 17, 2011</td>\n",
       "      <td>2011-07-17</td>\n",
       "      <td>28/5/1971</td>\n",
       "      <td>1971-05-28</td>\n",
       "      <td>5/1/2011</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>3/1/2017</td>\n",
       "      <td>2017-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             claim_date claim_date_formatted bio.birthday birthdate_formatted  \\\n",
       "554    January 20, 2012           2012-01-20   19/11/1947          1947-11-19   \n",
       "1983       May 14, 2012           2012-05-14    27/2/1954          1954-02-27   \n",
       "3944   November 5, 2010           2010-11-05   17/11/1949          1949-11-17   \n",
       "604   November 19, 2020           2020-11-19    11/2/1962          1962-02-11   \n",
       "1506      July 17, 2011           2011-07-17    28/5/1971          1971-05-28   \n",
       "\n",
       "         start start_formatted       end end_formatted  \n",
       "554   6/1/1987      1987-01-06  3/1/1989    1989-01-03  \n",
       "1983  4/1/1995      1995-01-04  3/1/1997    1997-01-03  \n",
       "3944  3/1/1991      1991-01-03  3/1/1993    1993-01-03  \n",
       "604   6/1/1999      1999-01-06  3/1/2001    2001-01-03  \n",
       "1506  5/1/2011      2011-01-05  3/1/2017    2017-01-03  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/clean-a-messy-date-column-with-mixed-formats-in-pandas-1a88808edbf7\n",
    "\n",
    "# standardise the format of all date columnns: YYYY-MM-DD\n",
    "df1['claim_date_formatted'] = pd.to_datetime(df1['claim_date'],infer_datetime_format=True)\n",
    "df1['birthdate_formatted'] = pd.to_datetime(df1['bio.birthday'],dayfirst=True)\n",
    "df1['start_formatted'] = pd.to_datetime(df1['start'],dayfirst=True)\n",
    "df1['end_formatted'] = pd.to_datetime(df1['end'],dayfirst=True)\n",
    "\n",
    "df1[['claim_date', 'claim_date_formatted', 'bio.birthday', 'birthdate_formatted', 'start', 'start_formatted',\n",
    "    'end', 'end_formatted']].sample(5) # standardised date format: YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAgeWhenClaimWasMade(birthdate, claimdate):\n",
    "    birth_year = birthdate.strftime('%Y-%m-%d').split('-')[0]\n",
    "    claim_year = claimdate.strftime('%Y-%m-%d').split('-')[0]\n",
    "    curr_age = int(claim_year) - int(birth_year)\n",
    "    return curr_age\n",
    "df1['claimmer age'] = df1.apply(lambda x: getAgeWhenClaimWasMade(x['birthdate formatted'], x['claim date formatted']), axis=1)\n",
    "df1[['birthdate formatted', 'claim date formatted', 'claimmer age']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df1['claimmer age'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "- Notice abnormally old ages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_age_idx = df1[df1['claimmer age'] > 94].index\n",
    "abnormal_age_names = df1.iloc[abnormal_age_idx].groupby('name').size().index\n",
    "df1.iloc[abnormal_age_idx].drop_duplicates(subset='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check thru politicians with dates that don't make sense\n",
    "# https://bioguide.congress.gov/\n",
    "abnormal_age_idx = df1[df1['claimmer age'] > 94].index\n",
    "abnormal_age_names = df1.iloc[abnormal_age_idx].groupby('name').size().index\n",
    "df1.iloc[abnormal_age_idx].drop_duplicates(subset='name')[['name','claimmer age', 'claim source',\n",
    "                                                           'birthdate formatted',\n",
    "                                                          'start formatted', 'end formatted','claim date formatted']] # 20 names to manually check thru and correct the dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "- The above are the politicians with anbormally old ages.\n",
    "- After checking on https://bioguide.congress.gov/, confirmed that they have already passed on (way) before claim date. \n",
    "- To drop these invalid rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(abnormal_age_names)} unique invalid politicians.\\n')\n",
    "print(f'They are found on {len(abnormal_age_idx)} rows which are to be dropped.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon inspection and googling we learn that this was due to a mismatch when joining the two tables(bio data and Politifact)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with these politicians who have alr passed on by index - abnormal_age_idx\n",
    "df1.drop(abnormal_age_idx, inplace=True)\n",
    "# reset df2 index\n",
    "df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "- To split the data into train and test datasets prior to applying countvectorizer / tfidfvectorizer/ other feature engineering steps to prevent data leakage.\n",
    "    \n",
    "    Reference:\n",
    "- https://stackoverflow.com/questions/54491953/can-i-use-countvectorizer-on-both-test-and-train-data-at-the-same-time-or-do-i-n\n",
    "- https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set \"accuracy\" as the y variable\n",
    "y = df1[\"accuracy\"] \n",
    "\n",
    "# Set everything other than accuracy as the X variables\n",
    "X = df1.drop(columns=[\"accuracy\"]) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer `claim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/52972368/select-top-n-tfidf-features-for-a-given-document\n",
    "\n",
    "train_claim = X_train['claim']\n",
    "test_claim = X_test['claim']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_claim_vec = TfidfVectorizer(lowercase=False, stop_words=\"english\")\n",
    "tfidf_claim_vec.fit(train_claim)\n",
    "tfidf_claim_vec_train = tfidf_claim_vec.transform(train_claim).toarray()\n",
    "tfidf_claim_vec_test = tfidf_claim_vec.transform(test_claim).toarray()\n",
    "\n",
    "tfidf_claim_vec_test.shape,tfidf_claim_vec_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subjectivity of `claim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "X_train['claim subjectivity'] = X_train['claim'].apply(lambda x:TextBlob(x).sentiment.subjectivity)\n",
    "X_test['claim subjectivity']  = X_test['claim'].apply(lambda x:TextBlob(x).sentiment.subjectivity)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.kdeplot(x=\"claim subjectivity\", data=X_train[y_train==0])\n",
    "sns.kdeplot(x=\"claim subjectivity\", data=X_train[y_train==1])\n",
    "plt.legend(['real','fake'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer `claim source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['claim source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_src = CountVectorizer(stop_words='english', lowercase=True)\n",
    "vectorizer_src.fit(X_train['claim source'].values)\n",
    "src_vec_train = vectorizer_src.transform(X_train['claim source']) # fit & transform on train\n",
    "\n",
    "# only transform on test\n",
    "src_vec_test = vectorizer_src.transform(X_test['claim source'].values)\n",
    "\n",
    "src_vec_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer `Issues`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_issues = CountVectorizer()\n",
    "vectorizer_issues.fit(X_train['issues'].values)\n",
    "issues_vec_train = vectorizer_issues.transform(X_train['issues']) # fit & transform on train\n",
    "issues_vec_test = vectorizer_issues.transform(X_test['issues'].values)\n",
    "issues_vec_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding (OHE) for Categorical Features\n",
    "\n",
    "- apply on categorical features: ['issue', 'state', 'bio.gender', 'type', 'party']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OHE all categorical variables tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['state', 'bio.gender', 'type', 'party']\n",
    "\n",
    "X_train_categorical = X_train[categorical_variables]\n",
    "X_test_categorical = X_test[categorical_variables]\n",
    "\n",
    "# One-hot encoding\n",
    "enc_lr = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "transformer_lr = make_column_transformer((enc_lr, categorical_variables), remainder=\"passthrough\")\n",
    "X_train_categorical = transformer_lr.fit_transform(X_train_categorical)\n",
    "X_test_categorical = transformer_lr.transform(X_test_categorical)\n",
    "\n",
    "age_train = X_train['claimmer age'].values.reshape(-1,1)\n",
    "age_test = X_test['claimmer age'].values.reshape(-1,1)\n",
    "subjectivity_train = X_train['claim subjectivity'].values.reshape(-1,1)\n",
    "subjectivity_test = X_test['claim subjectivity'].values.reshape(-1,1)\n",
    "\n",
    "X_train_vec = np.hstack([age_train, subjectivity_train, src_vec_train.toarray(), issues_vec_train.toarray(),tfidf_claim_vec_train])\n",
    "X_test_vec = np.hstack([age_test, subjectivity_test, src_vec_test.toarray(), issues_vec_test.toarray(), tfidf_claim_vec_test])\n",
    "\n",
    "# then combine with the numerical matrices of the other features \n",
    "X_train_combined = np.hstack([X_train_vec, X_train_categorical.toarray()])\n",
    "X_test_combined = np.hstack([X_test_vec, X_test_categorical.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['claimmer age','claim subjectivity']\n",
    "columns.extend(list(vectorizer_src.vocabulary_.keys()))\n",
    "columns.extend(list(vectorizer_issues.vocabulary_.keys()))\n",
    "columns.extend(list(tfidf_claim_vec.vocabulary_.keys()))\n",
    "lr_cols = transformer_lr.transformers_[0][1].categories_ #state, bio.gender, type, party\n",
    "for i in range(4):\n",
    "    columns.extend(lr_cols[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined.shape, X_test_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape,X_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=X_train_combined, columns=columns)\n",
    "df_train['accuracy'] = y_train.values\n",
    "df_train.to_csv(\"train bio.csv\")\n",
    "df_test = pd.DataFrame(data=X_test_combined, columns=columns)\n",
    "df_test['accuracy'] = y_test.values\n",
    "df_test.to_csv(\"test bio.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ab50e3e72d9027698848049824dee5f357392f7c8470ae2dc6788d02714a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
